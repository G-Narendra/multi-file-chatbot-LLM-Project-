# ğŸ“„ Multi-File Chatbot
An intelligent chatbot that allows users to upload multiple document formats (PDFs, TXTs, CSVs) and ask questions across them using Retrieval-Augmented Generation (RAG).

## ğŸš€ Features
Multi-File Support â€“ Upload PDFs, TXTs, and CSVs dynamically via the sidebar.

Document Parsing â€“ Extracts text seamlessly using PyMuPDF, TextLoader, and CSVLoader.

Chunking & Vector Storage â€“ Uses FAISS for efficient retrieval of document data.

LLM Integration â€“ Powered by open-source Llama 2 from Hugging Face (no OpenAI API required!).

Conversation Memory â€“ Retains chat history for better contextual understanding.

Streamlit UI â€“ Clean interface with sidebar file uploads and a center chat interface.

## ğŸ—ï¸ Project Structure
```bash
multi_file_chatbot/
â”‚â”€â”€ .env                         # Environment variables (API keys, config settings)
â”‚â”€â”€ .gitignore                   # Files to exclude from Git version control
â”‚â”€â”€ README.md                    # Project overview & setup instructions
â”‚â”€â”€ requirements.txt              # Dependencies list (Streamlit, LangChain, FAISS, etc.)
â”‚â”€â”€ app.py                        # Main Streamlit UI script
â”‚â”€â”€ config.yaml                   # Configuration settings (chunking, embeddings, vector store)
â”‚â”€â”€ data/                         # Temporary storage for uploaded files
â”‚â”€â”€ src/                          # Core project code
â”‚   â”œâ”€â”€ ui.py                     # Streamlit UI components (file uploader, chat interface)
â”‚   â”œâ”€â”€ file_processing.py        # File loaders for PDFs, CSVs, TXTs
â”‚   â”œâ”€â”€ chunking.py               # Text chunking & vector store management
â”‚   â”œâ”€â”€ retrieval.py              # Retrieval-Augmented Generation (RAG) logic
â”‚   â”œâ”€â”€ chatbot.py                # Chat handling, memory & response generation
â”‚â”€â”€ models/                        # Pre-trained embeddings & vector storage
â”‚â”€â”€ logs/                          # Directory for chat history logs

```

## âš™ï¸ Installation

### Clone the repository

```bash
git clone https://github.com/your-username/multi_file_chatbot.git
cd multi_file_chatbot
```
### Install dependencies
```bash
pip install -r requirements.txt
```
### Run the chatbot
```bash
streamlit run app.py
```
### ğŸ› ï¸ Configuration

Modify .env or config.yaml to customize:

Hugging Face model selection (MODEL_NAME).

Chunking parameters (CHUNK_SIZE, CHUNK_OVERLAP).

Vector store location (VECTOR_STORE_PATH).

### ğŸ’¡ How It Works
Step 1: Upload multiple files via the sidebar.

Step 2: Enter a query in the center chat box.

Step 3: The chatbot retrieves relevant document snippets and generates an answer.

### ğŸŒ Technologies Used
Streamlit â†’ UI Interface

LangChain â†’ RAG-based retrieval

FAISS â†’ Vector embeddings storage

Hugging Face Transformers â†’ Llama-2 for response generation

PyMuPDF, CSVLoader, TextLoader â†’ Document parsing